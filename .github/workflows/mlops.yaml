name: MLOps Workflow

on:
  push:
    branches:
      - main

  pull_request:

  workflow_dispatch:

jobs:
  train_model:
    runs-on: ubuntu-latest
    environment: mlops_test

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
 
    - name: Add dataset to DVC
      run: |
        mkdir -p ./data/chest_xray
        curl -L -o ./data/archive.zip https://www.kaggle.com/api/v1/datasets/download/paultimothymooney/chest-xray-pneumonia
        unzip ./data/archive.zip
        echo "ls"
        ls -la
        echo "ls de data"
        ls -la ./data
        echo "ls de chest_xray"
        ls -la ./chest_xray
        mv ./chest_xray/{*,.*} ./data/chest_xray
        echo "ls de data -> chest_xray"
        ls -la ./data/chest_xray
        dvc add data/chest_xray
      continue-on-error: true

    - name: Config aws credentials
      run: |
        dvc remote add -d myremote ${{ secrets.AWS_S3_BUCKET_URL }} --force
        dvc remote modify myremote access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        dvc remote modify myremote secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Pull data from DVC storage
      run: |
        dvc pull -vv -f
      continue-on-error: true
    
    - name: Train model
      run: |
        ls -la data
        ls -la data/chest_xray
        python3 src/train.py --data_path data/chest_xray --epochs 10 --batch_size 32
      continue-on-error: true

    - name: Push trained model to DVC
      run: |
        dvc add models/cancer_detection_model.*
        dvc push
